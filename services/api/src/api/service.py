import asyncio
from typing import Dict, Any, List, Optional, Union, Tuple
from datetime import datetime, timezone
import math
import aiohttp
from urllib.parse import urlparse
import os
import json
import re
import ssl
from services.radar_parser.llm_async_adapter import build_llm_payload

TIME_DECAY_HALF_LIFE_HOURS = 6.0
VELOCITY_SCALE = 3.0
MAX_CONFIRMATIONS_NORM = 3.0
STRICT_MODE = True

WEIGHTS = {
    "financial": 0.45,
    "recency": 0.20,
    "velocity": 0.15,
    "confirmations": 0.08,
    "source_rep": 0.07,
    "entities": 0.05,
}

FIN_ALLOWED_SECTIONS = (
    "business", "econom", "market", "finance", "company",
    "money", "realty", "tech", "commodit", "energy", "oil",
)
FIN_BLOCK_SECTIONS = (
    "sport", "sports", "politic", "photo", "style",
    "auto", "society", "culture", "lifestyle", "travel",
)

FIN_KEYWORDS = (
    "–∞–∫—Ü–∏", "–æ–±–ª–∏–≥–∞—Ü", "–¥–∏–≤–∏–¥–µ–Ω", "buyback", "–±–∞–π–±—ç–∫",
    "–≤—ã—Ä—É—á–∫", "–ø—Ä–∏–±—ã–ª", "—É–±—ã—Ç", "ebitda", "guidance", "–ø—Ä–æ–≥–Ω–æ–∑",
    "ipo", "spo", "—Ä–∞—Å–ø–∏—Å–∫–∞", "gdr", "adr",
    "—Å—Ç–∞–≤–∫", "–∫–ª—é—á–µ–≤", "—Ñ—Ä—Å", "—Ü–±", "–∏–Ω—Ñ–ª—è—Ü", "–≤–≤–ø", "pmi",
    "–æ—Ñ–∑", "–∫—É–ø–æ–Ω", "–¥–æ—Ö–æ–¥–Ω–æ—Å—Ç", "–∏–Ω–¥–µ–∫—Å", "—Ä—É–±–ª", "–∫—É—Ä—Å", "usd", "eur",
    "–Ω–µ—Ñ—Ç—å", "brent", "wti", "–≥–∞–∑", "—É–≥–æ–ª", "—É–≥–æ–ª—å", "–∑–æ–ª–æ—Ç", "–º–µ—Ç–∞–ª–ª",
    "—Å–∞–Ω–∫—Ü", "–Ω–¥—Å", "–¥–µ–º–ø—Ñ–µ—Ä", "—Ç–∞—Ä–∏—Ñ", "–∫–≤–æ—Ç", "–ø–æ—à–ª–∏–Ω", "–±—é–¥–∂–µ—Ç", "—Ä–≤–ø",
)

_TICKER_RE = re.compile(
    r"\b(?:MCX:|TQBR:)?[A-Z]{2,5}(?:\.[A-Z])?\b|USD/RUB|EUR/RUB|BRENT|WTI",
    re.IGNORECASE
)

OPENROUTER_API_KEY = os.getenv("OPENROUTER_API_KEY")
OPENROUTER_CHAT_URL = "https://openrouter.ai/api/v1/chat/completions"

SYSTEM_PROMPT = (
    '''–¢—ã ‚Äî RADAR.AI, –∞–≤—Ç–æ–Ω–æ–º–Ω—ã–π –∞–≥–µ–Ω—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –Ω–æ–≤–æ—Å—Ç–Ω—ã—Ö –ø–æ—Ç–æ–∫–æ–≤.
–¢–≤–æ—è –∑–∞–¥–∞—á–∞ ‚Äî –∏–∑ –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –≤—ã–¥–µ–ª—è—Ç—å —Å–∞–º—ã–µ –≥–æ—Ä—è—á–∏–µ —Å–æ–±—ã—Ç–∏—è –∏ —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å –∫–æ–º–ø–∞–∫—Ç–Ω—ã–π, –≤–µ—Ä–∏—Ñ–∏—Ü–∏—Ä—É–µ–º—ã–π JSON-–≤—ã–≤–æ–¥ –ø–æ —Å—Ö–µ–º–µ, –ø–æ–∫–∞–∑–∞–Ω–Ω–æ–π –Ω–∏–∂–µ.
–†–∞–±–æ—Ç–∞–π —Å—Ç—Ä–æ–≥–æ —Å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º–∏ –Ω–æ–≤–æ—Å—Ç—è–º–∏, –Ω–µ –ø—Ä–∏–¥—É–º—ã–≤–∞–π —Ñ–∞–∫—Ç–æ–≤.
–í—ã–≤–æ–¥–∏ —Ç–æ–ª—å–∫–æ JSON ‚Äî –±–µ–∑ –æ–ø–∏—Å–∞–Ω–∏–π –≤–Ω–µ –Ω–µ–≥–æ.
–§–æ—Ä–º–∞—Ç –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö:
[
  {
    "time": "2025-10-04T10:05:00Z",
    "source": "–†–ò–ê –ù–æ–≤–æ—Å—Ç–∏",
    "text": "–¶–ë –ø–æ–≤—ã—Å–∏–ª –∫–ª—é—á–µ–≤—É—é —Å—Ç–∞–≤–∫—É –¥–æ 18% –≥–æ–¥–æ–≤—ã—Ö, —á—Ç–æ–±—ã —Å–¥–µ—Ä–∂–∞—Ç—å –∏–Ω—Ñ–ª—è—Ü–∏—é.",
    "links_in_text": ["https://cbr.ru/press/"],
    "article_url": "https://ria.ru/economy/article123",
    "duplicates_count": 2
  }
]
–ê–ª–≥–æ—Ä–∏—Ç–º —Ä–∞–±–æ—Ç—ã: –°–Ω–∞—á–∞–ª–∞ –∑–∞–¥–∞–π —Å–∫–æ—Ä –º–µ—Ç—Ä–∏–∫–∞–º –æ—Ç 0 –¥–æ 1
1. materiality -  –æ—Ü–µ–Ω–∏ –Ω–∞—Å–∫–æ–ª—å–∫–æ —Å–æ–±—ã—Ç–∏–µ –≤–ª–∏—è–µ—Ç –Ω–∞ —ç–∫–æ–Ω–æ–º–∏–∫—É, –∫–æ–º–ø–∞–Ω–∏–∏, –±—é–¥–∂–µ—Ç –∏–ª–∏ –±–ª–∞–≥–æ—Å–æ—Å—Ç–æ—è–Ω–∏–µ.
2.  unexpectedness - –æ—Ü–µ–Ω–∏ –Ω–∞—Å–∫–æ–ª—å–∫–æ –Ω–æ–≤–æ—Å—Ç—å –Ω–µ–æ–∂–∏–¥–∞–Ω–Ω–∞ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ä—ã–Ω–∫–æ–≤ –∏–ª–∏ –æ–±—â–µ—Å—Ç–≤–∞ –≤ —Ü–µ–ª–æ–º.
3. spread_speed - –°–∫–æ—Ä–æ—Å—Ç—å —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–∏—è (–æ—Ü–µ–Ω–∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤, —Å—Å—ã–ª–æ–∫, –ø–æ—Å–º–æ—Ç—Ä–∏ –∫–∞–∫ —á–∞—Å—Ç–æ –Ω–æ–≤–æ—Å—Ç—å –≤—Å—Ç—Ä–µ—á–∞–µ—Ç—Å—è –≤ —Ä–∞–∑–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–∞—Ö).
4  breadth - –æ—Ü–µ–Ω–∏ –º–∞—Å—à—Ç–∞–± ‚Äî —Å–∫–æ–ª—å–∫–æ —Å—Ç—Ä–∞–Ω, –æ—Ç—Ä–∞—Å–ª–µ–π –∏–ª–∏ —Ä—ã–Ω–∫–æ–≤ –∑–∞—Ç—Ä–æ–Ω—É—Ç–æ.
5  credibility - –æ—Ü–µ–Ω–∏ –¥–æ—Å—Ç–æ–≤–µ—Ä–Ω–æ—Å—Ç—å –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤.
6  confirmations - –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–µ–∑–∞–≤–∏—Å–∏–º—ã—Ö –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–π (–Ω–∞–ø—Ä–∏–º–µ—Ä, —Ä–µ–≥—É–ª—è—Ç–æ—Ä—ã, –ø–æ–ª–∏—Ç–∏–∫–∏, —Ä—ã–Ω–æ—á–Ω—ã–µ –∞–Ω–∞–ª–∏—Ç–∏–∫–∏).
7  recency - —Å–≤–µ–∂–µ—Å—Ç—å –ø—É–±–ª–∏–∫–∞—Ü–∏–∏, —á–µ–º —Å—Ç–∞—Ä–µ–µ –Ω–æ–≤–æ—Å—Ç—å, —Ç–µ–º –º–µ–Ω—å—à–µ —Å–∫–æ—Ä.
8  public_reaction - —ç–º—É–ª–∏—Ä—É–π —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π –∏ –æ–±—â–µ—Å—Ç–≤–µ–Ω–Ω—ã–π –æ—Ç–∫–ª–∏–∫, –æ–ø–∏—Ä–∞–π—Å—è –Ω–∞ —Ä–µ–∞–∫—Ü–∏—é –Ω–∞ –ø–æ—Ö–æ–∂–∏–µ –∫–µ–π—Å—ã –≤ –ø—Ä–æ—à–ª–æ–º.
9  russia_weight - –æ—Ü–µ–Ω–∏ —Å—Ç–µ–ø–µ–Ω—å –≤–ª–∏—è–Ω–∏—è –Ω–∞ –†–æ—Å—Å–∏—é, —Ä—É–±–ª—å –∏–ª–∏ —Ä–æ—Å—Å–∏–π—Å–∫–∏—Ö –≥—Ä–∞–∂–¥–∞–Ω.

1.  –î–ª—è –∫–∞–∂–¥–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ –æ—Ü–µ–Ω–∏ hotness ‚àà [0,1] –ø–æ –¥–µ–≤—è—Ç–∏ –º–µ—Ç—Ä–∏–∫–∞–º:
materiality, unexpectedness, spread_speed, breadth, credibility, confirmations, recency, public_reaction, russia_weight.
2.  –†–∞—Å—Å—á–∏—Ç–∞–π base_hotness –ø–æ —Ñ–æ—Ä–º—É–ª–µ:
base_hotness = 0.25*materiality
             + 0.2*unexpectedness
             + 0.1*spread_speed
             + 0.1*breadth
             + 0.1*credibility
             + 0.05*confirmations
             + 0.05*recency
             + 0.1*public_reaction
             + 0.05*russia_weight
‚Ä¢  –ü—Ä–∏–º–µ–Ω—è–π –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∏:
‚Ä¢  –µ—Å–ª–∏ russia_weight ‚â• 0.7 ‚Üí √ó1.15 (cap 1.0)
‚Ä¢  –µ—Å–ª–∏ public_reaction ‚â• 0.8 –∏ credibility ‚â• 0.7 ‚Üí √ó1.10 (cap 1.0)
‚Ä¢  –°–æ–∑–¥–∞–π –∫–æ—Ä–æ—Ç–∫–∏–π —á–µ—Ä–Ω–æ–≤–∏–∫ –ø–æ—Å—Ç–∞ (draft), –æ–±—ä—è—Å–Ω–∏ –ø–æ—á–µ–º—É –Ω–æ–≤–æ—Å—Ç—å –≤–∞–∂–Ω–∞ –∏–º–µ–Ω–Ω–æ —Å–µ–π—á–∞—Å (why_now), –≤—ã–¥–µ–ª–∏ —Å—É—â–Ω–æ—Å—Ç–∏ (entities) –∏ –∏—Å—Ç–æ—á–Ω–∏–∫–∏ (sources). –í—ã–≤–µ–¥–∏ 3-5 –±—É–ª–ª–∏—Ç –ø–æ–∏–Ω—Ç–æ–≤ –ø–æ –ø—Ä–∏–º–µ—Ä—É –Ω–∏–∂–µ:
‚Ä¢  –í—ã–≤–µ–¥–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å—Ç—Ä–æ–≥–æ –ø–æ —à–∞–±–ª–æ–Ω—É –Ω–∏–∂–µ.
{
  "events": [
    {
      "headline": "–¶–ë –ø–æ–≤—ã—Å–∏–ª –∫–ª—é—á–µ–≤—É—é —Å—Ç–∞–≤–∫—É –¥–æ 18% –≥–æ–¥–æ–≤—ã—Ö",
      "hotness": 0.92,
      "why_now": "–†–µ—à–µ–Ω–∏–µ –Ω–µ–æ–∂–∏–¥–∞–Ω–Ω–æ –∏ –Ω–∞–ø—Ä—è–º—É—é –≤–ª–∏—è–µ—Ç –Ω–∞ –∏–ø–æ—Ç–µ–∫—É, –∫—Ä–µ–¥–∏—Ç—ã –∏ –∫—É—Ä—Å —Ä—É–±–ª—è. –í—ã–∑—ã–≤–∞–µ—Ç –±—É—Ä–Ω–æ–µ –æ–±—Å—É–∂–¥–µ–Ω–∏–µ –≤ –°–ú–ò –∏ —É –Ω–∞—Å–µ–ª–µ–Ω–∏—è.",
      "entities": ["–¶–ë –†–§", "—Ä—É–±–ª—å", "–∏–Ω—Ñ–ª—è—Ü–∏—è", "—Å—Ç–∞–≤–∫–∞"],
"timeline": [
            {"time": "2025-10-04T10:05:00Z", "event": "–ø–µ—Ä–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ"} 
          ]
"bullets": [
          "–†–µ—à–µ–Ω–∏–µ –ø—Ä–∏–Ω—è—Ç–æ –Ω–∞ –≤–Ω–µ–ø–ª–∞–Ω–æ–≤–æ–º –∑–∞—Å–µ–¥–∞–Ω–∏–∏ –¶–ë –†–§.",
          "–ò–Ω—Ñ–ª—è—Ü–∏–æ–Ω–Ω—ã–µ –æ–∂–∏–¥–∞–Ω–∏—è –ø—Ä–µ–≤—ã—Å–∏–ª–∏ –ø—Ä–æ–≥–Ω–æ–∑ –ú–∏–Ω—ç–∫–æ–Ω–æ–º—Ä–∞–∑–≤–∏—Ç–∏—è.",
          "–ë–∞–Ω–∫–∏ –Ω–∞—á–∞–ª–∏ –ø–µ—Ä–µ—Å–º–∞—Ç—Ä–∏–≤–∞—Ç—å —É—Å–ª–æ–≤–∏—è –ø–æ –∏–ø–æ—Ç–µ–∫–µ –∏ –∫—Ä–µ–¥–∏—Ç–∞–º."
        ],
        "citation": "–ò—Å—Ç–æ—á–Ω–∏–∫: –†–ò–ê –ù–æ–≤–æ—Å—Ç–∏, 2025-10-04"
üîπ –ü—Ä–∞–≤–∏–ª–∞ –ø–æ–≤–µ–¥–µ–Ω–∏—è —Å–∏—Å—Ç–µ–º—ã
    –í JSON –¢–ï–ö–°–¢ –°–¢–ê–¢–¨–ò –î–û–õ–ñ–ï–ù –ë–´–¢–¨ –ü–ï–†–ï–í–ï–î–ï–ù –ù–ê –†–£–°–°–ö–ò–ô –Ø–ó–´–ö, –≠–¢–û –û–ß–ï–ù–¨ –í–ê–ñ–ù–û
‚Ä¢  –ù–µ –¥–æ–±–∞–≤–ª—è–π –≤—ã–¥—É–º–∞–Ω–Ω—ã—Ö —Å–æ–±—ã—Ç–∏–π –∏–ª–∏ —Å—Å—ã–ª–æ–∫.
‚Ä¢  –ù–µ –ø–∏—à–∏ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤ –≤–Ω–µ JSON.
‚Ä¢  –°–æ—Ö—Ä–∞–Ω—è–π —Å–∂–∞—Ç–æ—Å—Ç—å –∏ —Å–º—ã—Å–ª–æ–≤—É—é –ø–ª–æ—Ç–Ω–æ—Å—Ç—å.
‚Ä¢  –ï—Å–ª–∏ –¥–∞–Ω–Ω—ã—Ö –º–∞–ª–æ, —Å–Ω–∏–∂–∞–π hotness.
‚Ä¢  –ü—Ä–∏ —Ä–∞–≤–Ω—ã—Ö hotness –æ—Ç–¥–∞–≤–∞–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç —Ç–µ–º, —á—Ç–æ –≤–ª–∏—è—é—Ç –Ω–∞ –±–ª–∞–≥–æ—Å–æ—Å—Ç–æ—è–Ω–∏–µ –Ω–∞—Å–µ–ª–µ–Ω–∏—è –∏–ª–∏ —ç–∫–æ–Ω–æ–º–∏–∫—É –†–§.
‚Ä¢  –í—Å–µ —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∏ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ.
‚Ä¢  RADAR.AI –¥–æ–ª–∂–µ–Ω –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å —Ç–æ–ª—å–∫–æ JSON –≤ –æ–ø–∏—Å–∞–Ω–Ω–æ–º –≤—ã—à–µ —Ñ–æ—Ä–º–∞—Ç–µ,
–≥–¥–µ –∫–∞–∂–¥–∞—è –∑–∞–ø–∏—Å—å –æ—Ç—Ä–∞–∂–∞–µ—Ç —Ä–µ–∞–ª—å–Ω–æ–µ —Å–æ–±—ã—Ç–∏–µ –∏ –∏–º–µ–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—É:
‚Ä¢  headline ‚Üí hotness ‚Üí why_now ‚Üí entities ‚Üí sources ‚Üí timeline ‚Üí draft
    '''
)

SUMMARY_SCHEMA_DESC = """–í–µ—Ä–Ω–∏ JSON —Å—Ç—Ä–æ–≥–æ –≤ —Ñ–æ—Ä–º–∞—Ç–µ:
{
  "impact_level": "–Ω–µ—Ç" | "–Ω–∏–∑–∫–æ–µ" | "—Å—Ä–µ–¥–Ω–µ–µ" | "–≤—ã—Å–æ–∫–æ–µ",
  "summary": "2‚Äì4 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –∏–ª–∏ 3‚Äì6 –±—É–ª–ª–∏—Ç–æ–≤ –ø—Ä–æ –≤–ª–∏—è–Ω–∏–µ –Ω–∞ RU —Ä—ã–Ω–æ–∫",
  "watchlist": ["—Ç–∏–∫–µ—Ä/—Å–µ–∫—Ç–æ—Ä", "..."],
  "rationale": "–∫–æ—Ä–æ—Ç–∫–æ –ø–æ—á–µ–º—É –≤—ã–±—Ä–∞–Ω —Ç–∞–∫–æ–π —É—Ä–æ–≤–µ–Ω—å"
}
–ï—Å–ª–∏ –≤–ª–∏—è–Ω–∏–µ –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç, impact_level="–Ω–µ—Ç" –∏ —è–≤–Ω–æ –Ω–∞–ø–∏—à–∏, —á—Ç–æ —Å—É—â–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –≤–ª–∏—è–Ω–∏—è –Ω–∞ RU —Ä—ã–Ω–æ–∫ –Ω–µ –æ–∂–∏–¥–∞–µ—Ç—Å—è.
–ù–µ –ø—Ä–∏–¥—É–º—ã–≤–∞–π —Ñ–∞–∫—Ç–æ–≤ –∏ –Ω–æ–≤—ã–µ —Å–æ–±—ã—Ç–∏—è. –û–ø–∏—Ä–∞—Ç—å—Å—è —Ç–æ–ª—å–∫–æ –Ω–∞ –≤—Ö–æ–¥–Ω—ã–µ items.
"""

SOURCE_REPUTATION: Dict[str, float] = {
    "reuters.com": 0.96,
    "bloomberg.com": 0.95,
    "ft.com": 0.93,
    "wsj.com": 0.92,
    "cnbc.com": 0.90,
    "economist.com": 0.90,
    "tass.ru": 0.60,
    "ria.ru": 0.55,
}


def _ssl_context() -> ssl.SSLContext:
    """–°–æ–∑–¥–∞—ë—Ç SSL-–∫–æ–Ω—Ç–µ–∫—Å—Ç —Å –¥–æ–≤–µ—Ä–µ–Ω–Ω—ã–º–∏ –∫–æ—Ä–Ω–µ–≤—ã–º–∏ —Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç–∞–º–∏; —É—á–∏—Ç—ã–≤–∞–µ—Ç SSL_CERT_FILE/SSL_CERT_DIR –∏ certifi (–µ—Å–ª–∏ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω)."""
    ctx = ssl.create_default_context()
    cafile = os.getenv("SSL_CERT_FILE")
    capath = os.getenv("SSL_CERT_DIR")
    if cafile or capath:
        try:
            ctx.load_verify_locations(cafile=cafile, capath=capath)
        except Exception:
            pass
    try:
        import certifi
        ctx.load_verify_locations(certifi.where())
    except Exception:
        pass
    return ctx


def time_decay_score(dt: datetime, now: Optional[datetime] = None,
                     half_life_hours: float = TIME_DECAY_HALF_LIFE_HOURS) -> float:
    """–≠–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–π —Å–∫–æ—Ä —Å–≤–µ–∂–µ—Å—Ç–∏ –≤ [0,1] –ø–æ –≤–æ–∑—Ä–∞—Å—Ç—É —Å–æ–±—ã—Ç–∏—è –∏ –ø–æ–ª—É-–ø–µ—Ä–∏–æ–¥—É."""
    now = now or datetime.now(timezone.utc)
    hours = max(0.0, (now - dt).total_seconds() / 3600.0)
    return 2 ** (-hours / half_life_hours)


def get_domain(url: str) -> str:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –¥–æ–º–µ–Ω –∏–∑ URL –∏–ª–∏ –ø—É—Å—Ç—É—é —Å—Ç—Ä–æ–∫—É –ø—Ä–∏ –æ—à–∏–±–∫–µ."""
    if not url:
        return ""
    try:
        return urlparse(url).netloc.lower()
    except Exception:
        return ""


def get_source_reputation(url_or_source: str) -> float:
    """–û—Ü–µ–Ω–∏–≤–∞–µ—Ç —Ä–µ–ø—É—Ç–∞—Ü–∏—é –∏—Å—Ç–æ—á–Ω–∏–∫–∞ –ø–æ –∏–∑–≤–µ—Å—Ç–Ω—ã–º –¥–æ–º–µ–Ω–∞–º; .gov –ø–æ–ª—É—á–∞–µ—Ç –ø–æ–≤—ã—à–µ–Ω–Ω—É—é –æ—Ü–µ–Ω–∫—É."""
    d = get_domain(url_or_source) or (url_or_source or "").lower()
    for known, rep in SOURCE_REPUTATION.items():
        if known in d:
            return rep
    if d.endswith(".gov") or ".gov." in d:
        return 0.9
    return 0.4


def _path_flags(url: str) -> Tuple[bool, bool]:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (allow, block) –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä—É–±—Ä–∏–∫ –≤ –ø—É—Ç–∏ URL."""
    u = (url or "").lower()
    allow = any(s in u for s in FIN_ALLOWED_SECTIONS)
    block = any(s in u for s in FIN_BLOCK_SECTIONS)
    return allow, block


def adjust_rep_by_path(rep: float, url: str) -> float:
    """–ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä—É–µ—Ç —Ä–µ–ø—É—Ç–∞—Ü–∏—é —Å —É—á—ë—Ç–æ–º —Ä—É–±—Ä–∏–∫–∏ URL (—Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã–µ/–Ω–µ—Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã–µ —Ä–∞–∑–¥–µ–ª—ã)."""
    allow, block = _path_flags(url or "")
    if allow:
        rep = min(1.0, rep + 0.10)
    if block:
        rep *= 0.5
    return rep


def normalize_velocity(repeats: float, age_hours: float, has_time: bool) -> float:
    """–ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç —Å–∫–æ—Ä–æ—Å—Ç—å —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–∏—è —á–µ—Ä–µ–∑ tanh(rate / VELOCITY_SCALE)."""
    if not has_time or repeats <= 1 or age_hours <= 0:
        return 0.0
    rate = repeats / max(age_hours, 1.0)
    return math.tanh(rate / VELOCITY_SCALE)


def normalize_confirmations(num_links: int, repeat_count: int) -> float:
    """–ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è, –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞—è MAX_CONFIRMATIONS_NORM."""
    return min(1.0, num_links / MAX_CONFIRMATIONS_NORM)


def normalize_entities_count(n: int) -> float:
    """–ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—É—â–Ω–æ—Å—Ç–µ–π/—Ç–∏–∫–µ—Ä–æ–≤ –¥–æ [0,1] —Å –º—è–≥–∫–∏–º –∫–∞–ø–æ–º –Ω–∞ 3."""
    return min(1.0, n / 3.0)


def compute_financial_score(text: str, url: str, entities: Optional[Dict[str, Any]]) -> float:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–∫–æ—Ä —Ñ–∏–Ω–∞–Ω—Å–æ–≤–æ–π —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ –ø–æ –∫–ª—é—á–∞–º, —Ç–∏–∫–µ—Ä–∞–º –∏ —Ä—É–±—Ä–∏–∫–µ URL."""
    t = (text or "").lower()
    allow, block = _path_flags(url)
    kw_hit = any(k in t for k in FIN_KEYWORDS)
    ticker_hit = bool(_TICKER_RE.search(t)) or bool((entities or {}).get("tickers"))
    score = 0.0
    if allow:
        score += 0.40
    if kw_hit:
        score += 0.35
    if ticker_hit:
        score += 0.35
    if block and not (kw_hit or ticker_hit):
        score *= 0.25
    return min(1.0, score)


def compute_hotness(features: Dict[str, float], weights: Dict[str, float] = WEIGHTS) -> float:
    """–°—á–∏—Ç–∞–µ—Ç –æ–±—â–∏–π hotness –∫–∞–∫ –≤–∑–≤–µ—à–µ–Ω–Ω—É—é —Å—É–º–º—É —Ñ–∏—á —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ–º [0,1]."""
    acc = 0.0
    for k, w in weights.items():
        acc += w * float(features.get(k, 0.0))
    return max(0.0, min(1.0, acc))


def make_why_now(features: Dict[str, Any]) -> str:
    """–§–æ—Ä–º–∏—Ä—É–µ—Ç –∫—Ä–∞—Ç–∫–æ–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ ¬´–ø–æ—á–µ–º—É —Å–µ–π—á–∞—Å¬ª –ø–æ –ø–æ—Ä–æ–≥–∞–º —Ñ–∏—á."""
    reasons = []
    if features.get("financial", 0.0) > 0.6:
        reasons.append("—Ñ–∏–Ω–∞–Ω—Å–æ–≤–∞—è —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å (—Å–∏–≥–Ω–∞–ª)")
    if features.get("recency", 0.0) > 0.6:
        reasons.append("—Å–≤–µ–∂–∞—è –ø—É–±–ª–∏–∫–∞—Ü–∏—è")
    if features.get("velocity", 0.0) > 0.6:
        reasons.append("–≤—ã—Å–æ–∫–∞—è —Å–∫–æ—Ä–æ—Å—Ç—å —Ä–µ–ø–æ—Å—Ç–æ–≤/–ø–æ–≤—Ç–æ—Ä–æ–≤")
    if features.get("confirmations", 0.0) > 0.5:
        reasons.append("–Ω–µ—Å–∫–æ–ª—å–∫–æ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–∞—é—â–∏—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤")
    if features.get("source_rep", 0.0) > 0.85:
        reasons.append("–∏—Å—Ç–æ—á–Ω–∏–∫ —Å –≤—ã—Å–æ–∫–æ–π —Ä–µ–ø—É—Ç–∞—Ü–∏–µ–π")
    if features.get("entities", 0.0) > 0.6:
        reasons.append("—à–∏—Ä–æ–∫–∏–π –æ—Ö–≤–∞—Ç –∞–∫—Ç–∏–≤–æ–≤")
    if not reasons:
        return "–ù–∞–∫–æ–ø–ª–µ–Ω–∏–µ –ø–æ–≤—Ç–æ—Ä–æ–≤ –∏ —É–º–µ—Ä–µ–Ω–Ω–∞—è –∞–∫—Ç—É–∞–ª—å–Ω–æ—Å—Ç—å."
    return ", ".join(reasons[:2]) + "."


def _coerce_items(data: Union[List[Dict[str, Any]], Dict[str, Any], None]) -> List[Dict[str, Any]]:
    """–ü—Ä–∏–≤–æ–¥–∏—Ç –≤—Ö–æ–¥ –∫ —Å–ø–∏—Å–∫—É —ç–ª–µ–º–µ–Ω—Ç–æ–≤ (list[dict])."""
    if data is None:
        return []
    if isinstance(data, list):
        return data
    if isinstance(data, dict) and isinstance(data.get("items"), list):
        return data["items"]
    return []


def _safe_parse_time(t: Any, fallback: datetime) -> Tuple[datetime, bool]:
    """–ü–∞—Ä—Å–∏—Ç ISO-–≤—Ä–µ–º—è (–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Å—É—Ñ—Ñ–∏–∫—Å 'Z'); –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç (dt_utc, has_time)."""
    if isinstance(t, datetime):
        return (t if t.tzinfo else t.replace(tzinfo=timezone.utc)), True
    if isinstance(t, str):
        s = t.strip()
        try:
            if s.endswith("Z"):
                s = s[:-1] + "+00:00"
            dt = datetime.fromisoformat(s)
            if dt.tzinfo is None:
                dt = dt.replace(tzinfo=timezone.utc)
            return dt, True
        except Exception:
            return fallback, False
    return fallback, False


def _openrouter_headers() -> Dict[str, str]:
    """–°–æ–±–∏—Ä–∞–µ—Ç HTTP-–∑–∞–≥–æ–ª–æ–≤–∫–∏ –¥–ª—è OpenRouter —Å –Ω–µ–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ–π –∞—Ç—Ä–∏–±—É—Ü–∏–µ–π –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è."""
    if not OPENROUTER_API_KEY:
        return {"Content-Type": "application/json"}
    headers = {
        "Authorization": f"Bearer {OPENROUTER_API_KEY}",
        "Content-Type": "application/json",
    }
    referer = os.getenv("OPENROUTER_SITE_URL", "https://finam-radar.local")
    title = os.getenv("OPENROUTER_APP_TITLE", "Finam Radar")
    headers["HTTP-Referer"] = referer
    headers["X-Title"] = title
    return headers


def _make_connector() -> aiohttp.TCPConnector:
    """–°–æ–∑–¥–∞—ë—Ç aiohttp-–∫–æ–Ω–Ω–µ–∫—Ç–æ—Ä —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π SSL (–º–æ–∂–Ω–æ –æ—Ç–∫–ª—é—á–∏—Ç—å —á–µ—Ä–µ–∑ OPENROUTER_INSECURE_SSL=1)."""
    if os.getenv("OPENROUTER_INSECURE_SSL") == "1":
        return aiohttp.TCPConnector(ssl=False)
    return aiohttp.TCPConnector(ssl=_ssl_context())


async def _post_openrouter(payload: Dict[str, Any]) -> Dict[str, Any]:
    """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç POST –Ω–∞ OpenRouter –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ä–∞—Å–ø–∞—Ä—Å–µ–Ω–Ω—ã–π JSON –ª–∏–±–æ –ø–æ–¥—Ä–æ–±–Ω—É—é –æ—à–∏–±–∫—É."""
    if not OPENROUTER_API_KEY:
        raise RuntimeError("OPENROUTER_API_KEY is not set")
    async with aiohttp.ClientSession(connector=_make_connector()) as s:
        async with s.post(OPENROUTER_CHAT_URL, json=payload, headers=_openrouter_headers(), timeout=60) as resp:
            text = await resp.text()
            if resp.status != 200:
                raise RuntimeError(f"OpenRouter HTTP {resp.status}: {text[:300]}")
            try:
                return json.loads(text)
            except Exception as e:
                raise RuntimeError(f"OpenRouter JSON parse error: {e}; payload: {text[:300]}")


async def generate_draft_openrouter(item: Dict[str, Any], system_prompt: str = SYSTEM_PROMPT) -> str:
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –¥—Ä–∞—Ñ—Ç –ø–æ –æ–¥–Ω–æ–º—É —Å–æ–±—ã—Ç–∏—é —á–µ—Ä–µ–∑ OpenRouter; –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–µ–∫—Å—Ç –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞."""
    if not OPENROUTER_API_KEY:
        return ""
    text = (item.get("text") or "")[:3000]
    links = item.get("links") or []
    entities = item.get("entities") or {}
    user_prompt = f"TEXT:\n{text}\n\nLINKS:\n{', '.join(links[:5])}\n\nENTITIES:\n{entities}\n"
    payload = {
        "model": "google/gemini-2.5-flash",
        "messages": [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt},
        ],
        "max_tokens": 800,
        "temperature": 0.3,
    }
    j = await _post_openrouter(payload)
    try:
        content = j["choices"][0]["message"]["content"]
        return (content or "").strip()
    except Exception as e:
        raise RuntimeError(f"OpenRouter schema mismatch: {e}; keys={list(j.keys())}")


async def generate_overall_summary_openrouter(items_out: List[Dict[str, Any]],
                                              system_prompt: str = SYSTEM_PROMPT) -> Dict[str, Any]:
    """–°—Ç—Ä–æ–∏—Ç —Å–≤–æ–¥–Ω–æ–µ —Ä–µ–∑—é–º–µ –ø–æ —Ä—ã–Ω–∫—É –∏–∑ —Ç–æ–ø-—Å–æ–±—ã—Ç–∏–π (LLM) –∏–ª–∏ –ª–æ–∫–∞–ª—å–Ω—ã–π —Ñ–æ–ª–±—ç–∫ –ø–æ hotness."""
    if not OPENROUTER_API_KEY:
        if not items_out:
            return {
                "impact_level": "–Ω–µ—Ç",
                "summary": "–†–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Å–æ–±—ã—Ç–∏–π –Ω–µ –≤—ã—è–≤–ª–µ–Ω–æ; –≤–ª–∏—è–Ω–∏—è –Ω–∞ —Ä–æ—Å—Å–∏–π—Å–∫–∏–π —Ä—ã–Ω–æ–∫ –Ω–µ—Ç.",
                "watchlist": [],
                "rationale": "–ü—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫ —Å–æ–±—ã—Ç–∏–π."
            }
        avg_hot = sum(i.get("hotness", 0.0) for i in items_out) / max(1, len(items_out))
        if avg_hot < 0.2:
            level, msg = "–Ω–µ—Ç", "–°—É—â–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –≤–ª–∏—è–Ω–∏—è –Ω–∞ —Ä–æ—Å—Å–∏–π—Å–∫–∏–π —Ä—ã–Ω–æ–∫ –Ω–µ –æ–∂–∏–¥–∞–µ—Ç—Å—è."
        elif avg_hot < 0.4:
            level, msg = "–Ω–∏–∑–∫–æ–µ", "–í–ª–∏—è–Ω–∏–µ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω–æ–µ; —Å—É—â–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –¥—Ä–∞–π–≤–µ—Ä–æ–≤ –¥–ª—è RU —Ä—ã–Ω–∫–∞ –Ω–µ –ø—Ä–æ—Å–º–∞—Ç—Ä–∏–≤–∞–µ—Ç—Å—è."
        elif avg_hot < 0.7:
            level, msg = "—Å—Ä–µ–¥–Ω–µ–µ", "–ï—Å—Ç—å —É–º–µ—Ä–µ–Ω–Ω—ã–µ —Ñ–∞–∫—Ç–æ—Ä—ã –≤–ª–∏—è–Ω–∏—è; —Ä–µ–∞–∫—Ü–∏—è –º–æ–∂–µ—Ç –±—ã—Ç—å —Ç–æ—á–µ—á–Ω–æ–π –ø–æ —Å–µ–∫—Ç–æ—Ä–∞–º."
        else:
            level, msg = "–≤—ã—Å–æ–∫–æ–µ", "–í—ã—Å–æ–∫–∞—è –∑–Ω–∞—á–∏–º–æ—Å—Ç—å —Å–æ–±—ã—Ç–∏–π; –≤–æ–∑–º–æ–∂–Ω–æ –≤–ª–∏—è–Ω–∏–µ –Ω–∞ –∏–Ω–¥–µ–∫—Å –∏ —Ä—É–±–ª—å."
        return {"impact_level": level, "summary": msg, "watchlist": [],
                "rationale": f"–õ–æ–∫–∞–ª—å–Ω—ã–π —Ñ–æ–ª–±—ç–∫ –ø–æ —Å—Ä–µ–¥–Ω–µ–º—É hotness={avg_hot:.2f}."}

    compact_items = []
    for x in items_out[:10]:
        compact_items.append({
            "headline": x.get("headline"),
            "hotness": x.get("hotness"),
            "why_now": x.get("why_now"),
            "time": (x.get("timeline") or [{}])[0].get("time"),
            "financial": round((x.get("features") or {}).get("financial", 0.0), 3),
            "source_rep": round((x.get("features") or {}).get("source_rep", 0.0), 3),
            "recency": round((x.get("features") or {}).get("recency", 0.0), 3),
            "velocity": round((x.get("features") or {}).get("velocity", 0.0), 3),
            "confirmations": round((x.get("features") or {}).get("confirmations", 0.0), 3),
            "entities_count": len((x.get("entities") or {}).get("tickers", [])) if isinstance(x.get("entities"),
                                                                                              dict) else 0
        })

    user_prompt = (
        "–ù–∏–∂–µ –∏—Ç–æ–≥–æ–≤—ã–π —Å–ø–∏—Å–æ–∫ —Å–æ–±—ã—Ç–∏–π (items) —Å –æ—Ü–µ–Ω–∫–∞–º–∏ hotness –∏ –ø—Ä–∏—á–∏–Ω–∞–º–∏ why_now.\n"
        "–°—Ñ–æ—Ä–º–∏—Ä—É–π –∫–æ–Ω—Å–æ–ª–∏–¥–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —Ä–µ–∑—é–º–µ –¥–ª—è —Ä–æ—Å—Å–∏–π—Å–∫–æ–≥–æ —Ä—ã–Ω–∫–∞: –∏–Ω–¥–µ–∫—Å—ã, —Ä—É–±–ª—å, –û–§–ó, —Å–µ–∫—Ç–æ—Ä–∞/—Ç–∏–∫–µ—Ä—ã.\n"
        "–ï—Å–ª–∏ –≤–ª–∏—è–Ω–∏–µ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ ‚Äî —Ç–∞–∫ –∏ —Å–∫–∞–∂–∏.\n\n"
        f"items = {json.dumps(compact_items, ensure_ascii=False)}\n\n"
        f"{SUMMARY_SCHEMA_DESC}"
    )
    payload = {
        "model": "google/gemini-2.5-pro",
        "messages": [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt},
        ],
        "max_tokens": 600,
        "temperature": 0.2,
    }
    j = await _post_openrouter(payload)
    content = j["choices"][0]["message"]["content"].strip()
    try:
        parsed = json.loads(content)
        if not isinstance(parsed, dict):
            raise ValueError("not a dict")
        for k in ("impact_level", "summary", "watchlist", "rationale"):
            parsed.setdefault(k, "" if k != "watchlist" else [])
        return parsed
    except Exception:
        return {
            "impact_level": "–Ω–∏–∑–∫–æ–µ" if len(items_out) and (
                        sum(i.get("hotness", 0.0) for i in items_out) / len(items_out) < 0.4) else "—Å—Ä–µ–¥–Ω–µ–µ",
            "summary": content[:1200],
            "watchlist": [],
            "rationale": "–ú–æ–¥–µ–ª—å –≤–µ—Ä–Ω—É–ª–∞ –Ω–µ-JSON; –∫–æ–Ω—Ç–µ–Ω—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω –∫–∞–∫ summary."
        }


async def get_top_k(window: int = 24, k: int = 5,
                    items: Optional[Union[List[Dict[str, Any]], Dict[str, Any]]] = None) -> Dict[str, Any]:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–æ–ø-k –≥–æ—Ä—è—á–∏—Ö —Å–æ–±—ã—Ç–∏–π –∏ —Å–≤–æ–¥–∫—É –≤–ª–∏—è–Ω–∏—è –Ω–∞ —Ä—ã–Ω–æ–∫ –†–§."""
    data = _coerce_items(items)
    if not data:
        data = await build_llm_payload(window)
        try:
            open('data.json', 'w').write(json.dumps(data, ensure_ascii=False, indent=2))
        except Exception:
            pass

    now = datetime.now(timezone.utc)
    items_out: List[Dict[str, Any]] = []

    for it in data:
        raw_time = it.get("–í—Ä–µ–º—è –≤—ã—Ö–æ–¥–∞") or it.get("time") or it.get("time_published")
        t_dt, has_time = _safe_parse_time(raw_time, now)
        age_hours = max(0.0, (now - t_dt).total_seconds() / 3600.0)
        recency = time_decay_score(t_dt, now) if has_time else 0.0

        repeats = float(it.get("–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏–π", it.get("–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–≤—Ç–æ—Ä—è—à–µ–∫", it.get("repeat_count", 1))))
        inner_links = (
                it.get("—Å–ø–∏—Å–æ–∫ —Å—Å—ã–ª–æ–∫ –≤–Ω—É—Ç—Ä–∏ —Ç–µ–∫—Å—Ç–∞")
                or it.get("links_in_text")
                or it.get("links", [])
                or []
        )
        num_links = len(inner_links)

        url = (
                it.get("—Å—Å—ã–ª–∫–∞ –Ω–∞ —Å–∞–º—É —Å—Ç–∞—Ç—å—é")
                or it.get("article_url")
                or it.get("url")
                or (it.get("source") if (it.get("source") and str(it.get("source")).startswith("http")) else "")
        )
        source_field = it.get("–∏—Å—Ç–æ—á–Ω–∏–∫") or it.get("source") or ""
        source_rep = get_source_reputation(url or source_field)
        source_rep = adjust_rep_by_path(source_rep, url or "")

        entities = it.get("entities") or it.get("—Å–ø–∏—Å–æ–∫ —Å—É—â–Ω–æ—Å—Ç–µ–π") or {}
        entities_norm = normalize_entities_count(
            len(entities.get("tickers", [])) if isinstance(entities, dict) else 0
        )

        text_for_score = it.get("—Ç–µ–∫—Å—Ç —Å—Ç–∞—Ç—å–∏") or it.get("text") or ""
        fin_score = compute_financial_score(text_for_score, url or "", entities)
        if fin_score < 0.30:
            continue

        if STRICT_MODE:
            low = text_for_score.lower()
            strict_hit = bool(_TICKER_RE.search(text_for_score)) or any(
                key in low for key in
                ("—Å—Ç–∞–≤–∫", "–∏–Ω—Ñ–ª—è—Ü", "–∏–Ω–¥–µ–∫—Å", "brent", "usd/rub", "eur/rub", "–æ—Ñ–∑", "–∫—É–ø–æ–Ω", "–¥–æ—Ö–æ–¥–Ω–æ—Å—Ç")
            )
            if not strict_hit:
                continue

        velocity = normalize_velocity(repeats, age_hours, has_time)
        confirmations = normalize_confirmations(num_links, int(repeats))

        features = {
            "financial": fin_score,
            "recency": recency,
            "velocity": velocity,
            "confirmations": confirmations,
            "source_rep": source_rep,
            "entities": entities_norm
        }

        hotness = compute_hotness(features)
        why_now = make_why_now(features)

        draft = ""
        if OPENROUTER_API_KEY:
            try:
                draft = await generate_draft_openrouter({
                    "text": text_for_score,
                    "links": inner_links,
                    "entities": entities
                })
            except Exception as e:
                draft = f"LLM error: {e}"

        headline = None
        if draft:
            first_line = draft.splitlines()[0].strip()
            if first_line:
                headline = first_line[:120]
        if not headline:
            txt = (text_for_score or "").strip()
            headline = (txt.split(".")[0] if "." in txt else txt)[:120] or None

        items_out.append({
            "headline": headline,
            "hotness": round(hotness, 4),
            "why_now": why_now,
            "entities": entities,
            "sources": (inner_links[:5]) if inner_links else ([url] if url else []),
            "timeline": [{"time": t_dt.isoformat(), "url": url}],
            "draft": draft,
            "dedup_group": it.get("dedup_group") or f"article:{url or (it.get('id') or '')}",
            "raw_item": it,
            "features": features
        })

    items_out.sort(key=lambda x: x["hotness"], reverse=True)
    top_items = items_out[:k]
    overall_summary = await generate_overall_summary_openrouter(top_items)

    return {
        "items": top_items,
        "generated_at": now.isoformat(),
        "k": k,
        "overall_summary": overall_summary
    }
